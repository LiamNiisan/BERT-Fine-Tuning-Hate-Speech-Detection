{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a3626f-4cdc-4d78-ad6d-3473540e4542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from src.data_collection import get_data\n",
    "from src.models import HateDataset, DistilBERTMultiClass, get_distil_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8da8fa1-c809-453f-a938-805f4dc1fd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration ucberkeley-dlab--measuring-hate-speech-7cb9b0b8e4d0e1dd\n",
      "Reusing dataset parquet (C:\\Users\\UTKARSH\\.cache\\huggingface\\datasets\\parquet\\ucberkeley-dlab--measuring-hate-speech-7cb9b0b8e4d0e1dd\\0.0.0\\0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67a174d7ed2444ca7504c975c7d74c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UTKARSH\\miniconda3\\envs\\env_deep\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1653: FutureWarning: Calling DistilBertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "hate_speech_ucb = get_data()\n",
    "HYPERPARAMS = get_distil_hyperparams()\n",
    "\n",
    "model_path = HYPERPARAMS[\"MODEL_PATH\"]\n",
    "vocab_path = HYPERPARAMS[\"VOCAB_PATH\"]\n",
    "\n",
    "TOKENIZER = DistilBertTokenizer.from_pretrained(vocab_path)\n",
    "MAX_LEN = HYPERPARAMS[\"MAX_LEN\"]\n",
    "device = HYPERPARAMS[\"DEVICE\"]\n",
    "\n",
    "N_SAMPLES = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34c3781e-12c5-4cf7-944e-5e2a39b8c442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hatespeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>! thank u! im transmasc and generally present ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!Go fuck yourself faggot!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!flair [I love women and minorities]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!flair [death to all niggers and gays]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\" 'convoluted' genealogy of Jesus\"; was that c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\" *gulhfg* that's the sound of your mom suckin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\" Did you notice a sign out front that said de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\" F those ugly idiots \" \" I cant stand useless...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\" Fuck you niggas ion give a fuck no more nigg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\" Happy Independence Day to all my fellow sout...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\" I got women tryna sneak me through there doo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\" I wish ur crack mom aborted you\" well guess ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\" Pray for him\" ha! The filthy traitor would b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\" i believe\" So you don't acttually know, and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\" if I get pregnant by a nigga in Mexico, ima ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\" is dat so hard for yu niggas to doðŸ˜• y'all wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\" she hates mexicans \" got me cryiNGGGG tears ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"'She's the one using antisemitic tropes' I sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\".. Soo what are you gonna pick love? ~\" ðŸ’¬ to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"...This bill actually poses a devastating and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  hatespeech\n",
       "0   ! thank u! im transmasc and generally present ...           0\n",
       "1                           !Go fuck yourself faggot!           1\n",
       "2                !flair [I love women and minorities]           0\n",
       "3              !flair [death to all niggers and gays]           1\n",
       "4   \" 'convoluted' genealogy of Jesus\"; was that c...           0\n",
       "5   \" *gulhfg* that's the sound of your mom suckin...           1\n",
       "6   \" Did you notice a sign out front that said de...           1\n",
       "7   \" F those ugly idiots \" \" I cant stand useless...           0\n",
       "8   \" Fuck you niggas ion give a fuck no more nigg...           1\n",
       "9   \" Happy Independence Day to all my fellow sout...           0\n",
       "10  \" I got women tryna sneak me through there doo...           1\n",
       "11  \" I wish ur crack mom aborted you\" well guess ...           0\n",
       "12  \" Pray for him\" ha! The filthy traitor would b...           1\n",
       "13  \" i believe\" So you don't acttually know, and ...           0\n",
       "14  \" if I get pregnant by a nigga in Mexico, ima ...           0\n",
       "15  \" is dat so hard for yu niggas to doðŸ˜• y'all wa...           1\n",
       "16  \" she hates mexicans \" got me cryiNGGGG tears ...           0\n",
       "17  \"'She's the one using antisemitic tropes' I sa...           0\n",
       "18  \".. Soo what are you gonna pick love? ~\" ðŸ’¬ to ...           0\n",
       "19  \"...This bill actually poses a devastating and...           0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_speech_sample = hate_speech_ucb[:N_SAMPLES]#.sample(N_SAMPLES, random_state=585)\n",
    "hate_speech_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18e1a8af-c9dd-48de-9d54-6eb619afce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HateDataset(hate_speech_sample, TOKENIZER, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b3124bd-2a18-4468-9d61-2e809542311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_params = HYPERPARAMS[\"TEST_PARAMS\"]\n",
    "\n",
    "sample_loader = DataLoader(dataset, **sample_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1f4ac66-b674-4124-9a71-068ce5d7b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = hate_speech_sample[\"hatespeech\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "398b7484-5f7a-423c-81c5-93d987a81e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBERTMultiClass(\n",
       "  (l1): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distil_model = DistilBERTMultiClass(n_classes=N_CLASSES)\n",
    "distil_model.load_state_dict(torch.load(model_path))\n",
    "distil_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "934b59b4-5f2f-4c1c-87ec-3a052d1151df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loader):\n",
    "    model.eval()\n",
    "    fin_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in tqdm(enumerate(loader)):\n",
    "            ids = data[\"ids\"].to(device, dtype=torch.long)\n",
    "            mask = data[\"mask\"].to(device, dtype=torch.long)\n",
    "            token_type_ids = data[\"token_type_ids\"].to(device, dtype=torch.long)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "998b8b0c-53e3-4694-913f-fbc22ea73f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\UTKARSH\\miniconda3\\envs\\env_deep\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2263: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "20it [00:02,  9.75it/s]\n"
     ]
    }
   ],
   "source": [
    "distil_outputs = predict(distil_model, sample_loader)\n",
    "distil_outputs = np.argmax(distil_outputs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d251d2d1-2132-4cd1-bc92-bfa8bcb434cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UTKARSH\\AppData\\Local\\Temp\\ipykernel_11844\\617290997.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hate_speech_sample[\"DistilBERT_pred\"] = distil_outputs\n"
     ]
    }
   ],
   "source": [
    "hate_speech_sample[\"DistilBERT_pred\"] = distil_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b28a5ba2-0a88-447e-a294-8ffbaee6f6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>DistilBERT_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>! thank u! im transmasc and generally present ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!Go fuck yourself faggot!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!flair [I love women and minorities]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!flair [death to all niggers and gays]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\" 'convoluted' genealogy of Jesus\"; was that c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\" *gulhfg* that's the sound of your mom suckin...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\" Did you notice a sign out front that said de...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\" F those ugly idiots \" \" I cant stand useless...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\" Fuck you niggas ion give a fuck no more nigg...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\" Happy Independence Day to all my fellow sout...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\" I got women tryna sneak me through there doo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\" I wish ur crack mom aborted you\" well guess ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\" Pray for him\" ha! The filthy traitor would b...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\" i believe\" So you don't acttually know, and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\" if I get pregnant by a nigga in Mexico, ima ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\" is dat so hard for yu niggas to doðŸ˜• y'all wa...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\" she hates mexicans \" got me cryiNGGGG tears ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"'She's the one using antisemitic tropes' I sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\".. Soo what are you gonna pick love? ~\" ðŸ’¬ to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"...This bill actually poses a devastating and...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  hatespeech  \\\n",
       "0   ! thank u! im transmasc and generally present ...           0   \n",
       "1                           !Go fuck yourself faggot!           1   \n",
       "2                !flair [I love women and minorities]           0   \n",
       "3              !flair [death to all niggers and gays]           1   \n",
       "4   \" 'convoluted' genealogy of Jesus\"; was that c...           0   \n",
       "5   \" *gulhfg* that's the sound of your mom suckin...           1   \n",
       "6   \" Did you notice a sign out front that said de...           1   \n",
       "7   \" F those ugly idiots \" \" I cant stand useless...           0   \n",
       "8   \" Fuck you niggas ion give a fuck no more nigg...           1   \n",
       "9   \" Happy Independence Day to all my fellow sout...           0   \n",
       "10  \" I got women tryna sneak me through there doo...           1   \n",
       "11  \" I wish ur crack mom aborted you\" well guess ...           0   \n",
       "12  \" Pray for him\" ha! The filthy traitor would b...           1   \n",
       "13  \" i believe\" So you don't acttually know, and ...           0   \n",
       "14  \" if I get pregnant by a nigga in Mexico, ima ...           0   \n",
       "15  \" is dat so hard for yu niggas to doðŸ˜• y'all wa...           1   \n",
       "16  \" she hates mexicans \" got me cryiNGGGG tears ...           0   \n",
       "17  \"'She's the one using antisemitic tropes' I sa...           0   \n",
       "18  \".. Soo what are you gonna pick love? ~\" ðŸ’¬ to ...           0   \n",
       "19  \"...This bill actually poses a devastating and...           0   \n",
       "\n",
       "    DistilBERT_pred  \n",
       "0                 0  \n",
       "1                 1  \n",
       "2                 0  \n",
       "3                 1  \n",
       "4                 0  \n",
       "5                 1  \n",
       "6                 1  \n",
       "7                 0  \n",
       "8                 1  \n",
       "9                 0  \n",
       "10                0  \n",
       "11                0  \n",
       "12                1  \n",
       "13                0  \n",
       "14                1  \n",
       "15                1  \n",
       "16                0  \n",
       "17                0  \n",
       "18                0  \n",
       "19                0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_speech_sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_deep]",
   "language": "python",
   "name": "conda-env-env_deep-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
